use std::sync::Arc;
use tokio::sync::Mutex;

use futures::{channel::mpsc, StreamExt};
use solana_entry::entry::Entry;
use tonic::transport::Channel;

use log::error;
use solana_sdk::transaction::VersionedTransaction;

use crate::common::AnyResult;
use crate::streaming::event_parser::{EventParserFactory, Protocol, UnifiedEvent};

use crate::protos::shredstream::shredstream_proxy_client::ShredstreamProxyClient;
use crate::protos::shredstream::SubscribeEntriesRequest;
use solana_sdk::pubkey::Pubkey;

// é»˜è®¤é…ç½®å¸¸é‡
const DEFAULT_CHANNEL_SIZE: usize = 1000;
const DEFAULT_BATCH_SIZE: usize = 100;
const DEFAULT_BATCH_TIMEOUT_MS: u64 = 5;

/// ShredStreamæ‰¹å¤„ç†é…ç½®
#[derive(Debug, Clone)]
pub struct ShredBatchConfig {
    /// æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤ï¼š100ï¼‰
    pub batch_size: usize,
    /// æ‰¹å¤„ç†è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼Œé»˜è®¤ï¼š10msï¼‰
    pub batch_timeout_ms: u64,
    /// æ˜¯å¦å¯ç”¨æ‰¹å¤„ç†ï¼ˆé»˜è®¤ï¼štrueï¼‰
    pub enabled: bool,
}

impl Default for ShredBatchConfig {
    fn default() -> Self {
        Self {
            batch_size: DEFAULT_BATCH_SIZE,
            batch_timeout_ms: DEFAULT_BATCH_TIMEOUT_MS,
            enabled: true,
        }
    }
}

/// ShredStreamèƒŒå‹é…ç½®
#[derive(Debug, Clone)]
pub struct ShredBackpressureConfig {
    /// é€šé“å¤§å°ï¼ˆé»˜è®¤ï¼š10000ï¼‰
    pub channel_size: usize,
}

impl Default for ShredBackpressureConfig {
    fn default() -> Self {
        Self {
            channel_size: DEFAULT_CHANNEL_SIZE,
        }
    }
}

/// ShredStreamå®Œæ•´é…ç½®
#[derive(Debug, Clone)]
pub struct ShredClientConfig {
    /// æ‰¹å¤„ç†é…ç½®
    pub batch: ShredBatchConfig,
    /// èƒŒå‹é…ç½®
    pub backpressure: ShredBackpressureConfig,
    /// æ˜¯å¦å¯ç”¨æ€§èƒ½ç›‘æ§ï¼ˆé»˜è®¤ï¼šfalseï¼‰
    pub enable_metrics: bool,
}

impl Default for ShredClientConfig {
    fn default() -> Self {
        Self {
            batch: ShredBatchConfig::default(),
            backpressure: ShredBackpressureConfig::default(),
            enable_metrics: false,
        }
    }
}

impl ShredClientConfig {
    /// åˆ›å»ºé«˜æ€§èƒ½é…ç½®ï¼ˆé€‚åˆé«˜å¹¶å‘åœºæ™¯ï¼‰
    pub fn high_performance() -> Self {
        Self {
            batch: ShredBatchConfig {
                batch_size: 200,
                batch_timeout_ms: 5,
                enabled: true,
            },
            backpressure: ShredBackpressureConfig {
                channel_size: 20000,
            },
            enable_metrics: true,
        }
    }

    /// åˆ›å»ºä½å»¶è¿Ÿé…ç½®ï¼ˆé€‚åˆå®æ—¶åœºæ™¯ï¼‰
    pub fn low_latency() -> Self {
        Self {
            batch: ShredBatchConfig {
                batch_size: 10,
                batch_timeout_ms: 1,
                enabled: false, // ç¦ç”¨æ‰¹å¤„ç†ï¼Œå³æ—¶å¤„ç†
            },
            backpressure: ShredBackpressureConfig {
                channel_size: 1000,
            },
            enable_metrics: false,
        }
    }
}

/// ShredStreamæ€§èƒ½ç›‘æ§æŒ‡æ ‡
#[derive(Debug, Clone)]
pub struct ShredPerformanceMetrics {
    pub events_processed: u64,
    pub events_per_second: f64,
    pub average_processing_time_ms: f64,
    pub min_processing_time_ms: f64,
    pub max_processing_time_ms: f64,
    pub memory_usage_mb: f64,
    pub last_update_time: std::time::Instant,
    pub events_in_window: u64,
    pub window_start_time: std::time::Instant,
}

impl Default for ShredPerformanceMetrics {
    fn default() -> Self {
        Self::new()
    }
}

impl ShredPerformanceMetrics {
    pub fn new() -> Self {
        let now = std::time::Instant::now();
        Self {
            events_processed: 0,
            events_per_second: 0.0,
            average_processing_time_ms: 0.0,
            min_processing_time_ms: f64::MAX,
            max_processing_time_ms: 0.0,
            memory_usage_mb: 0.0,
            last_update_time: now,
            events_in_window: 0,
            window_start_time: now,
        }
    }
}

#[derive(Clone)]
pub struct ShredStreamGrpc {
    shredstream_client: Arc<ShredstreamProxyClient<Channel>>,
    config: ShredClientConfig,
    metrics: Arc<Mutex<ShredPerformanceMetrics>>,
}

struct TransactionWithSlot {
    transaction: VersionedTransaction,
    slot: u64,
}

/// ShredStreamæ‰¹å¤„ç†å™¨
pub struct ShredBatchProcessor<F>
where
    F: FnMut(Vec<Box<dyn UnifiedEvent>>) + Send + Sync + 'static,
{
    callback: F,
    batch: Vec<Box<dyn UnifiedEvent>>,
    batch_size: usize,
    timeout_ms: u64,
    last_flush_time: std::time::Instant,
}

impl<F> ShredBatchProcessor<F>
where
    F: FnMut(Vec<Box<dyn UnifiedEvent>>) + Send + Sync + 'static,
{
    pub fn new(callback: F, batch_size: usize, timeout_ms: u64) -> Self {
        Self {
            callback,
            batch: Vec::with_capacity(batch_size),
            batch_size,
            timeout_ms,
            last_flush_time: std::time::Instant::now(),
        }
    }

    pub fn add_event(&mut self, event: Box<dyn UnifiedEvent>) {
        self.batch.push(event);
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°æ‰¹æ¬¡
        if self.batch.len() >= self.batch_size || self.should_flush_by_timeout() {
            self.flush();
        }
    }

    pub fn flush(&mut self) {
        if !self.batch.is_empty() {
            let events = std::mem::replace(&mut self.batch, Vec::with_capacity(self.batch_size));
            (self.callback)(events);
            self.last_flush_time = std::time::Instant::now();
        }
    }

    fn should_flush_by_timeout(&self) -> bool {
        self.last_flush_time.elapsed().as_millis() >= self.timeout_ms as u128
    }
}

impl ShredStreamGrpc {
    /// åˆ›å»ºå®¢æˆ·ç«¯ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    pub async fn new(endpoint: String) -> AnyResult<Self> {
        Self::new_with_config(endpoint, ShredClientConfig::default()).await
    }

    /// åˆ›å»ºå®¢æˆ·ç«¯ï¼Œä½¿ç”¨è‡ªå®šä¹‰é…ç½®
    pub async fn new_with_config(endpoint: String, config: ShredClientConfig) -> AnyResult<Self> {
        let shredstream_client = ShredstreamProxyClient::connect(endpoint.clone()).await?;
        Ok(Self {
            shredstream_client: Arc::new(shredstream_client),
            config,
            metrics: Arc::new(Mutex::new(ShredPerformanceMetrics::new())),
        })
    }

    /// åˆ›å»ºé«˜æ€§èƒ½å®¢æˆ·ç«¯ï¼ˆé€‚åˆé«˜å¹¶å‘åœºæ™¯ï¼‰
    pub async fn new_high_performance(endpoint: String) -> AnyResult<Self> {
        Self::new_with_config(endpoint, ShredClientConfig::high_performance()).await
    }

    /// åˆ›å»ºä½å»¶è¿Ÿå®¢æˆ·ç«¯ï¼ˆé€‚åˆå®æ—¶åœºæ™¯ï¼‰
    pub async fn new_low_latency(endpoint: String) -> AnyResult<Self> {
        Self::new_with_config(endpoint, ShredClientConfig::low_latency()).await
    }

    /// è·å–å½“å‰é…ç½®
    pub fn get_config(&self) -> &ShredClientConfig {
        &self.config
    }

    /// æ›´æ–°é…ç½®
    pub fn update_config(&mut self, config: ShredClientConfig) {
        self.config = config;
    }

    /// è·å–æ€§èƒ½æŒ‡æ ‡
    pub async fn get_metrics(&self) -> ShredPerformanceMetrics {
        let metrics = self.metrics.lock().await;
        metrics.clone()
    }

    /// å¯ç”¨æˆ–ç¦ç”¨æ€§èƒ½ç›‘æ§
    pub fn set_enable_metrics(&mut self, enabled: bool) {
        self.config.enable_metrics = enabled;
    }

    /// æ‰“å°æ€§èƒ½æŒ‡æ ‡
    pub async fn print_metrics(&self) {
        let metrics = self.get_metrics().await;
        println!("ğŸ“Š ShredStream Performance Metrics:");
        println!("   Events Processed: {}", metrics.events_processed);
        println!("   Events/Second: {:.2}", metrics.events_per_second);
        println!("   Avg Processing Time: {:.2}ms", metrics.average_processing_time_ms);
        println!("   Min Processing Time: {:.2}ms", metrics.min_processing_time_ms);
        println!("   Max Processing Time: {:.2}ms", metrics.max_processing_time_ms);
        println!("   Memory Usage: {:.2}MB", metrics.memory_usage_mb);
        println!("---");
    }

    /// å¯åŠ¨è‡ªåŠ¨æ€§èƒ½ç›‘æ§ä»»åŠ¡
    pub async fn start_auto_metrics_monitoring(&self) {
        // æ£€æŸ¥æ˜¯å¦å¯ç”¨æ€§èƒ½ç›‘æ§
        if !self.config.enable_metrics {
            return; // å¦‚æœæœªå¯ç”¨æ€§èƒ½ç›‘æ§ï¼Œä¸å¯åŠ¨ç›‘æ§ä»»åŠ¡
        }

        let grpc_clone = self.clone();
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(tokio::time::Duration::from_secs(10));
            loop {
                interval.tick().await;
                grpc_clone.print_metrics().await;
            }
        });
    }

    /// æ›´æ–°æ€§èƒ½æŒ‡æ ‡
    async fn update_metrics(&self, events_processed: u64, processing_time_ms: f64) {
        // æ£€æŸ¥æ˜¯å¦å¯ç”¨æ€§èƒ½ç›‘æ§
        if !self.config.enable_metrics {
            return; // å¦‚æœæœªå¯ç”¨æ€§èƒ½ç›‘æ§ï¼Œç›´æ¥è¿”å›
        }

        let mut metrics = self.metrics.lock().await;
        let now = std::time::Instant::now();
        
        metrics.events_processed += events_processed;
        metrics.events_in_window += events_processed;
        metrics.last_update_time = now;
        
        // æ›´æ–°æœ€å¿«å’Œæœ€æ…¢å¤„ç†æ—¶é—´
        if processing_time_ms < metrics.min_processing_time_ms {
            metrics.min_processing_time_ms = processing_time_ms;
        }
        if processing_time_ms > metrics.max_processing_time_ms {
            metrics.max_processing_time_ms = processing_time_ms;
        }
        
        // è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´
        if metrics.events_processed > 0 {
            metrics.average_processing_time_ms = 
                (metrics.average_processing_time_ms * (metrics.events_processed - events_processed) as f64 + processing_time_ms) 
                / metrics.events_processed as f64;
        }
        
        // åŸºäºæ—¶é—´çª—å£è®¡ç®—æ¯ç§’å¤„ç†äº‹ä»¶æ•°ï¼ˆ5ç§’çª—å£ï¼‰
        let window_duration = std::time::Duration::from_secs(5);
        if now.duration_since(metrics.window_start_time) >= window_duration {
            let window_seconds = now.duration_since(metrics.window_start_time).as_secs_f64();
            if window_seconds > 0.0 && metrics.events_in_window > 0 {
                metrics.events_per_second = metrics.events_in_window as f64 / window_seconds;
            } else {
                // å¦‚æœçª—å£å†…æ²¡æœ‰äº‹ä»¶ï¼Œä¿æŒä¹‹å‰çš„é€Ÿç‡æˆ–è®¾ä¸º0
                metrics.events_per_second = 0.0;
            }
            
            // é‡ç½®çª—å£
            metrics.events_in_window = 0;
            metrics.window_start_time = now;
        } else {
            // å¦‚æœçª—å£è¿˜æ²¡æ»¡ï¼Œä¸æ›´æ–° events_per_secondï¼Œä¿æŒä¹‹å‰çš„è®¡ç®—å€¼
            // è¿™æ ·å¯ä»¥é¿å…å› ä¸ºå•æ¬¡æ‰¹å¤„ç†æ—¶é—´æ³¢åŠ¨å¯¼è‡´çš„æŒ‡æ ‡è·³è·ƒ
        }
        
        // ä¼°ç®—å†…å­˜ä½¿ç”¨ï¼ˆåŸºäºå¤„ç†çš„äº‹ä»¶æ•°é‡ï¼‰
        metrics.memory_usage_mb = metrics.events_processed as f64 * 0.001; // æ¯ä¸ªäº‹ä»¶çº¦1KB
    }

    /// è®¢é˜…ShredStreamäº‹ä»¶ï¼ˆæ”¯æŒæ‰¹å¤„ç†å’Œå³æ—¶å¤„ç†ï¼‰
    pub async fn shredstream_subscribe<F>(
        &self,
        protocols: Vec<Protocol>,
        bot_wallet: Option<Pubkey>,
        callback: F,
    ) -> AnyResult<()>
    where
        F: Fn(Box<dyn UnifiedEvent>) + Send + Sync + 'static,
    {
        // å¯åŠ¨è‡ªåŠ¨æ€§èƒ½ç›‘æ§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.config.enable_metrics {
            self.start_auto_metrics_monitoring().await;
        }
        
        let request = tonic::Request::new(SubscribeEntriesRequest {});
        let mut client = (*self.shredstream_client).clone();
        let stream = client.subscribe_entries(request).await?.into_inner();
        let (tx, rx) = mpsc::channel::<TransactionWithSlot>(self.config.backpressure.channel_size);
        
        // æ ¹æ®é…ç½®é€‰æ‹©å¤„ç†æ¨¡å¼
        if self.config.batch.enabled {
            // æ‰¹å¤„ç†æ¨¡å¼
            self.process_with_batch(stream, tx, rx, protocols, bot_wallet, callback).await
        } else {
            // å³æ—¶å¤„ç†æ¨¡å¼
            self.process_immediate(stream, tx, rx, protocols, bot_wallet, callback).await
        }
    }

    /// æ‰¹å¤„ç†æ¨¡å¼
    async fn process_with_batch<F>(
        &self,
        mut stream: tonic::codec::Streaming<crate::protos::shredstream::Entry>,
        mut tx: mpsc::Sender<TransactionWithSlot>,
        mut rx: mpsc::Receiver<TransactionWithSlot>,
        protocols: Vec<Protocol>,
        bot_wallet: Option<Pubkey>,
        callback: F,
    ) -> AnyResult<()>
    where
        F: Fn(Box<dyn UnifiedEvent>) + Send + Sync + 'static,
    {
        // åˆ›å»ºæ‰¹å¤„ç†å™¨ï¼Œå°†å•ä¸ªäº‹ä»¶å›è°ƒè½¬æ¢ä¸ºæ‰¹é‡å›è°ƒ
        let batch_callback = move |events: Vec<Box<dyn UnifiedEvent>>| {
            for event in events {
                callback(event);
            }
        };
        
        let mut batch_processor = ShredBatchProcessor::new(
            batch_callback, 
            self.config.batch.batch_size, 
            self.config.batch.batch_timeout_ms
        );
        
        tokio::spawn(async move {
            while let Some(message) = stream.next().await {
                match message {
                    Ok(msg) => {
                        if let Ok(entries) = bincode::deserialize::<Vec<Entry>>(&msg.entries) {
                            for entry in entries {
                                for transaction in entry.transactions {
                                    let _ = tx.try_send(TransactionWithSlot {
                                        transaction: transaction.clone(),
                                        slot: msg.slot,
                                    });
                                }
                            }
                        }
                    }
                    Err(error) => {
                        error!("Stream error: {error:?}");
                        break;
                    }
                }
            }
        });

        let self_clone = self.clone();
        while let Some(transaction_with_slot) = rx.next().await {
            if let Err(e) = self_clone.process_transaction_with_batch(
                transaction_with_slot,
                protocols.clone(),
                bot_wallet,
                &mut batch_processor,
            )
            .await
            {
                error!("Error processing transaction: {e:?}");
            }
        }
        
        // å¤„ç†å‰©ä½™çš„äº‹ä»¶
        batch_processor.flush();

        Ok(())
    }

    /// å³æ—¶å¤„ç†æ¨¡å¼
    async fn process_immediate<F>(
        &self,
        mut stream: tonic::codec::Streaming<crate::protos::shredstream::Entry>,
        mut tx: mpsc::Sender<TransactionWithSlot>,
        mut rx: mpsc::Receiver<TransactionWithSlot>,
        protocols: Vec<Protocol>,
        bot_wallet: Option<Pubkey>,
        callback: F,
    ) -> AnyResult<()>
    where
        F: Fn(Box<dyn UnifiedEvent>) + Send + Sync + 'static,
    {
        tokio::spawn(async move {
            while let Some(message) = stream.next().await {
                match message {
                    Ok(msg) => {
                        if let Ok(entries) = bincode::deserialize::<Vec<Entry>>(&msg.entries) {
                            for entry in entries {
                                for transaction in entry.transactions {
                                    let _ = tx.try_send(TransactionWithSlot {
                                        transaction: transaction.clone(),
                                        slot: msg.slot,
                                    });
                                }
                            }
                        }
                    }
                    Err(error) => {
                        error!("Stream error: {error:?}");
                        break;
                    }
                }
            }
        });

        let self_clone = self.clone();
        while let Some(transaction_with_slot) = rx.next().await {
            if let Err(e) = self_clone.process_transaction_immediate(
                transaction_with_slot,
                protocols.clone(),
                bot_wallet,
                &callback,
            )
            .await
            {
                error!("Error processing transaction: {e:?}");
            }
        }

        Ok(())
    }

    /// å³æ—¶å¤„ç†å•ä¸ªäº¤æ˜“
    async fn process_transaction_immediate<F>(
        &self,
        transaction_with_slot: TransactionWithSlot,
        protocols: Vec<Protocol>,
        bot_wallet: Option<Pubkey>,
        callback: &F,
    ) -> AnyResult<()>
    where
        F: Fn(Box<dyn UnifiedEvent>) + Send + Sync,
    {
        let start_time = std::time::Instant::now();
        let program_received_time_ms = chrono::Utc::now().timestamp_millis();
        let slot = transaction_with_slot.slot;
        let versioned_tx = transaction_with_slot.transaction;
        let signature = versioned_tx.signatures[0];

        // é¢„åˆ†é…å‘é‡å®¹é‡
        let mut all_events = Vec::with_capacity(protocols.len() * 2);
        
        for protocol in protocols {
            let parser = EventParserFactory::create_parser(protocol.clone());
            let events = parser
                .parse_versioned_transaction(
                    &versioned_tx,
                    &signature.to_string(),
                    Some(slot),
                    None,
                    program_received_time_ms,
                    bot_wallet,
                )
                .await
                .unwrap_or_else(|_e| vec![]);
            all_events.extend(events);
        }
        
        // ä¿å­˜äº‹ä»¶æ•°é‡ç”¨äºæ—¥å¿—è®°å½•
        let event_count = all_events.len();
        
        // å³æ—¶å¤„ç†äº‹ä»¶
        for event in all_events {
            callback(event);
        }
        
        // æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        let processing_time = start_time.elapsed();
        let processing_time_ms = processing_time.as_millis() as f64;
        
        // å®é™…è°ƒç”¨æ€§èƒ½æŒ‡æ ‡æ›´æ–°
        self.update_metrics(event_count as u64, processing_time_ms).await;
        
        // è®°å½•æ…¢å¤„ç†æ“ä½œ
        if processing_time_ms > 5.0 {
            log::warn!("ShredStream transaction processing took {}ms for {} events", 
                      processing_time_ms, event_count);
        }

        Ok(())
    }

    async fn process_transaction_with_batch<F>(
        &self,
        transaction_with_slot: TransactionWithSlot,
        protocols: Vec<Protocol>,
        bot_wallet: Option<Pubkey>,
        batch_processor: &mut ShredBatchProcessor<F>,
    ) -> AnyResult<()>
    where
        F: FnMut(Vec<Box<dyn UnifiedEvent>>) + Send + Sync + 'static,
    {
        let start_time = std::time::Instant::now();
        let program_received_time_ms = chrono::Utc::now().timestamp_millis();
        let slot = transaction_with_slot.slot;
        let versioned_tx = transaction_with_slot.transaction;
        let signature = versioned_tx.signatures[0];

        // é¢„åˆ†é…å‘é‡å®¹é‡
        let mut all_events = Vec::with_capacity(protocols.len() * 2);
        
        for protocol in protocols {
            let parser = EventParserFactory::create_parser(protocol.clone());
            let events = parser
                .parse_versioned_transaction(
                    &versioned_tx,
                    &signature.to_string(),
                    Some(slot),
                    None,
                    program_received_time_ms,
                    bot_wallet,
                )
                .await
                .unwrap_or_else(|_e| vec![]);
            all_events.extend(events);
        }
        
        // ä¿å­˜äº‹ä»¶æ•°é‡ç”¨äºæ—¥å¿—è®°å½•
        let event_count = all_events.len();
        
        // ä½¿ç”¨æ‰¹å¤„ç†å™¨å¤„ç†äº‹ä»¶
        for event in all_events {
            batch_processor.add_event(event);
        }
        
        // æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        let processing_time = start_time.elapsed();
        let processing_time_ms = processing_time.as_millis() as f64;
        
        // å®é™…è°ƒç”¨æ€§èƒ½æŒ‡æ ‡æ›´æ–°
        self.update_metrics(event_count as u64, processing_time_ms).await;
        
        // è®°å½•æ…¢å¤„ç†æ“ä½œ
        if processing_time_ms > 5.0 {
            log::warn!("ShredStream transaction processing took {}ms for {} events", 
                      processing_time_ms, event_count);
        }

        Ok(())
    }
}